"""Test script for anomaly detection system."""

import json
from pathlib import Path
from datetime import datetime

print("ğŸš¨ Nsight AI Anomaly Detection System Test")
print("=" * 50)

def test_anomaly_detection():
    """Test the anomaly detection system."""
    
    # Test 1: Train Anomaly Detection
    print("\nğŸ“‹ Test 1: Training Anomaly Detection Models")
    print("-" * 40)
    
    try:
        from src.ml.anomaly_detector import AnomalyDetector
        
        data_file = "data/expenses.csv"
        
        if not Path(data_file).exists():
            print(f"âŒ Data file not found: {data_file}")
            print("ğŸ”„ Creating synthetic data first...")
            
            # Generate synthetic data if needed
            import subprocess
            result = subprocess.run(['python', '-m', 'src.data_generation.synthetic_data'], 
                                  capture_output=True, text=True)
            if result.returncode != 0:
                print("âŒ Failed to generate synthetic data")
                return False
            print("âœ… Synthetic data generated")
        
        detector = AnomalyDetector()
        
        # Load historical data
        if not detector.load_historical_data(data_file):
            print("âŒ Failed to load historical data")
            return False
        
        # Train models
        training_results = detector.train_anomaly_models()
        
        if 'error' in training_results:
            print(f"âŒ Training failed: {training_results['error']}")
            return False
        
        print("âœ… Anomaly detection training completed!")
        print(f"  ğŸ“Š Training samples: {training_results['training_samples']}")
        print(f"  ğŸŒ² Isolation forest score: {training_results['isolation_forest_score']:.3f}")
        print(f"  ğŸ“ˆ Statistical baselines: {training_results['statistical_baseline_score']}")
        print(f"  ğŸ” Pattern analysis: {training_results['pattern_analysis_score']} patterns")
        print(f"  ğŸ¯ Anomaly threshold: {training_results['anomaly_threshold']}")
        
        # Test 2: Detect Anomalies
        print("\nğŸ“‹ Test 2: Anomaly Detection Analysis")
        print("-" * 40)
        
        anomaly_results = detector.detect_anomalies()
        
        if 'error' in anomaly_results:
            print(f"âŒ Detection failed: {anomaly_results['error']}")
            return False
        
        print("âœ… Anomaly detection completed!")
        print(f"  ğŸ’° Total expenses analyzed: {anomaly_results['total_expenses']}")
        print(f"  ğŸš¨ Anomalies detected: {anomaly_results['anomalies_detected']}")
        print(f"  ğŸ“ˆ Anomaly rate: {anomaly_results['anomaly_rate']:.1f}%")
        
        if anomaly_results['severity_breakdown']:
            print(f"  ğŸ“‹ Severity breakdown:")
            for severity, count in anomaly_results['severity_breakdown'].items():
                print(f"     â€¢ {severity}: {count}")
        
        # Test 3: Show Top Anomalies
        anomalies = anomaly_results.get('anomalies', [])
        if anomalies:
            print(f"\nğŸ”´ Top Anomalies Found:")
            for i, anomaly in enumerate(anomalies[:5], 1):
                severity_icon = "ğŸ”´" if anomaly['severity'] == 'High' else "ğŸŸ¡" if anomaly['severity'] == 'Medium' else "ğŸŸ "
                print(f"  {i}. {severity_icon} ${anomaly['amount']:,.0f} - {anomaly['vendor']} ({anomaly['department']})")
                print(f"      Date: {anomaly['date']} | Score: {anomaly['anomaly_score']:.2f}")
                print(f"      Reasons: {', '.join(anomaly['reasons'])}")
            
            if len(anomalies) > 5:
                print(f"      ... and {len(anomalies) - 5} more anomalies")
        else:
            print("âœ… No anomalies detected - spending patterns appear normal")
        
        # Test 4: Anomaly Summary
        print("\nğŸ“‹ Test 3: Anomaly Summary & Insights")
        print("-" * 40)
        
        summary = detector.get_anomaly_summary(anomaly_results)
        
        if 'error' in summary:
            print(f"âŒ Summary failed: {summary['error']}")
            return False
        
        if summary.get('message'):
            print(f"âœ… {summary['message']}")
        else:
            print(f"ğŸš¨ Anomaly Rate: {summary['anomaly_rate']:.1f}%")
            print(f"ğŸ“Š Total Anomalies: {summary['total_anomalies']}")
            
            if summary.get('department_summary'):
                print(f"\nğŸ¢ Department Analysis:")
                dept_sorted = sorted(summary['department_summary'].items(), 
                                   key=lambda x: x[1]['count'], reverse=True)[:3]
                
                for dept, data in dept_sorted:
                    print(f"  â€¢ {dept}: {data['count']} anomalies, ${data['total_amount']:,.0f}, avg score: {data['avg_anomaly_score']:.2f}")
            
            if summary.get('recommendations'):
                print(f"\nğŸ’¡ Key Recommendations:")
                for rec in summary['recommendations']:
                    print(f"  â€¢ {rec}")
        
        # Test 5: Export Report
        print("\nğŸ“‹ Test 4: Export Anomaly Report")
        print("-" * 40)
        
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)
        
        report_file = f"reports/anomaly_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        if detector.export_anomaly_report(anomaly_results, report_file):
            print(f"âœ… Anomaly report exported: {report_file}")
            
            # Verify report file
            with open(report_file, 'r') as f:
                report_data = json.load(f)
            
            print(f"  ğŸ“„ Report contains: {len(report_data)} sections")
            print(f"  ğŸ“Š File size: {Path(report_file).stat().st_size} bytes")
        else:
            print("âŒ Failed to export report")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_cli_commands():
    """Test CLI commands for anomaly detection."""
    print("\nğŸ“‹ Test 5: CLI Command Testing")
    print("-" * 40)
    
    import subprocess
    
    commands = [
        ['python', '-m', 'src.cli', 'train-anomaly'],
        ['python', '-m', 'src.cli', 'detect-anomalies'],
        ['python', '-m', 'src.cli', 'anomaly-summary'],
    ]
    
    for cmd in commands:
        try:
            print(f"  ğŸ”„ Testing: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                print(f"  âœ… Command successful")
                # Show first few lines of output
                lines = result.stdout.strip().split('\n')[:3]
                for line in lines:
                    if line.strip():
                        print(f"    {line}")
            else:
                print(f"  âŒ Command failed: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            print(f"  â° Command timed out")
            return False
        except Exception as e:
            print(f"  âŒ Error running command: {e}")
            return False
    
    return True

def show_usage_examples():
    """Show usage examples for anomaly detection."""
    print("\nğŸ“‹ Usage Examples")
    print("=" * 50)
    
    print("ğŸš¨ Anomaly Detection Commands:")
    print()
    print("1. Train anomaly detection models:")
    print("   py -m src.cli train-anomaly")
    print("   py -m src.cli train-anomaly data/expenses.csv")
    print()
    print("2. Detect anomalies in spending:")
    print("   py -m src.cli detect-anomalies")
    print("   py -m src.cli detect-anomalies --threshold 0.7")
    print("   py -m src.cli detect-anomalies --save-report")
    print()
    print("3. Show anomaly summary:")
    print("   py -m src.cli anomaly-summary")
    print("   py -m src.cli anomaly-summary data/custom_expenses.csv")
    print()
    print("ğŸ¯ Anomaly threshold:")
    print("  â€¢ 0.5-0.6: Sensitive (more anomalies detected)")
    print("  â€¢ 0.6-0.7: Balanced (default)")
    print("  â€¢ 0.7-0.8: Conservative (fewer false positives)")
    print()
    print("ğŸ“Š Anomaly scoring:")
    print("  â€¢ High (â‰¥0.8): Immediate review required")
    print("  â€¢ Medium (0.7-0.8): Review recommended")
    print("  â€¢ Low (0.6-0.7): Monitor for patterns")

if __name__ == "__main__":
    try:
        # Run all tests
        success = True
        
        success &= test_anomaly_detection()
        success &= test_cli_commands()
        
        show_usage_examples()
        
        print("\n" + "=" * 50)
        if success:
            print("ğŸ‰ All Anomaly Detection Tests PASSED!")
            print("âœ… Anomaly detection system is ready for production use")
            print()
            print("ğŸš€ Next Steps:")
            print("  â€¢ Train models: py -m src.cli train-anomaly")
            print("  â€¢ Detect anomalies: py -m src.cli detect-anomalies")
            print("  â€¢ Set up automated monitoring")
            print("  â€¢ Configure alert thresholds")
        else:
            print("âŒ Some tests FAILED - check output above")
            print("ğŸ”§ Please review the error messages and try again")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Tests cancelled by user")
    except Exception as e:
        print(f"\nâŒ Test suite failed: {e}")
        import traceback
        traceback.print_exc() 